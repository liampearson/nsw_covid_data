{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "mobility_data.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PPbp5ls6x52L",
        "outputId": "c8683ac9-e799-4f25-fc05-48e9a576c323"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from os.path import join\n",
        "import math\n",
        "\n",
        "from google.colab import drive\n",
        "\n",
        "# authentication for google sheets\n",
        "from gspread_dataframe import set_with_dataframe\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "import gspread\n",
        "from oauth2client.client import GoogleCredentials as GC\n",
        "gc = gspread.authorize(GC.get_application_default())\n",
        "\n",
        "drive.mount('/content/drive/')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GuzauzPMRkMI"
      },
      "source": [
        "write_directory = '/content/drive/My Drive/covid19data/'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "cSNiKYkSx8Bo",
        "outputId": "7b5940eb-c9c7-4dad-b278-a787e5643e8b"
      },
      "source": [
        "# region csv is located at: https://www.gstatic.com/covid19/mobility/Region_Mobility_Report_CSVs.zip\n",
        "\n",
        "#download the zip file\n",
        "!wget https://www.gstatic.com/covid19/mobility/Region_Mobility_Report_CSVs.zip\n",
        "\n",
        "#unzip the file\n",
        "!unzip Region_Mobility_Report_CSVs.zip\n",
        "\n",
        "#get the AU file\n",
        "REGION = \"AU\"\n",
        "df2020 = pd.read_csv(\"2020_\"+REGION+\"_Region_Mobility_Report.csv\")\n",
        "df2021 = pd.read_csv(\"2021_\"+REGION+\"_Region_Mobility_Report.csv\")\n",
        "df = df2020.append(df2021)\n",
        "\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-07-25 11:17:54--  https://www.gstatic.com/covid19/mobility/Region_Mobility_Report_CSVs.zip\n",
            "Resolving www.gstatic.com (www.gstatic.com)... 173.194.215.94, 2607:f8b0:400c:c09::5e\n",
            "Connecting to www.gstatic.com (www.gstatic.com)|173.194.215.94|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 52808975 (50M) [application/zip]\n",
            "Saving to: ‘Region_Mobility_Report_CSVs.zip.1’\n",
            "\n",
            "Region_Mobility_Rep 100%[===================>]  50.36M  70.9MB/s    in 0.7s    \n",
            "\n",
            "2021-07-25 11:17:54 (70.9 MB/s) - ‘Region_Mobility_Report_CSVs.zip.1’ saved [52808975/52808975]\n",
            "\n",
            "Archive:  Region_Mobility_Report_CSVs.zip\n",
            "replace 2020_AE_Region_Mobility_Report.csv? [y]es, [n]o, [A]ll, [N]one, [r]ename: "
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z4QRYuu87_iQ"
      },
      "source": [
        "#inspect the data (see first 5 rows)\n",
        "df.columns"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k7LVUlP4yis3"
      },
      "source": [
        "#notes for AU:\n",
        "#df.sub_region_1 = State = [, 'Australian Capital Territory', 'New South Wales', 'Northern Territory', 'Queensland', 'South Australia', 'Tasmania', 'Victoria', 'Western Australia']\n",
        "#df.sub_region_2 = councils\n",
        "#df.metro_area = null\n",
        "#df.iso_3166_2_code.unique() = [nan, 'AU-ACT', 'AU-NSW', 'AU-NT', 'AU-QLD', 'AU-SA', 'AU-TAS','AU-VIC', 'AU-WA']\n",
        "#df[df.iso_3166_2_code=='AU-NSW'].date.tail()\n",
        "#df[df.date==max(df.date)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eypdniIj6QIp"
      },
      "source": [
        "## Get place_id lookup (equivalent of index_v)\n",
        "Google assigned a unique `place_id` for each Country / sub_region_1 / sub_region_2...etc\n",
        "\n",
        "For each unique place_id, we will get 3 fields:\n",
        "- Country / sub_region_1 / sub_region_2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gE3mAGYg5oq7"
      },
      "source": [
        "# initialise an empty dataframe for the place_id lookup\n",
        "place_id_lookup = pd.DataFrame()\n",
        "\n",
        "for placeid in df.place_id.unique():\n",
        "  #ensure there is only one country_region for this placeid\n",
        "  if (len(df[df['place_id']==placeid]['country_region'].unique())!=1):\n",
        "    print(\"ERROR!!!\")\n",
        "  country_region = df[df['place_id']==placeid]['country_region'].unique()[0]\n",
        "\n",
        "  #ensure there is only one iso_3166_2_code for this placeid\n",
        "  if (len(df[df['place_id']==placeid]['iso_3166_2_code'].unique())!=1):\n",
        "    print(\"ERROR!!!\")\n",
        "  iso_3166_2_code = df[df['place_id']==placeid]['iso_3166_2_code'].unique()[0]\n",
        "\n",
        "  #ensure there is only one sub_region_1 for this placeid\n",
        "  if (len(df[df['place_id']==placeid]['sub_region_1'].unique())!=1):\n",
        "    print(\"ERROR!!!\")\n",
        "  sub_region_1 = df[df['place_id']==placeid]['sub_region_1'].unique()[0]\n",
        "\n",
        "  #ensure there is only one sub_region_2 for this placeid\n",
        "  if (len(df[df['place_id']==placeid]['sub_region_2'].unique())!=1):\n",
        "    print(\"ERROR!!!\")\n",
        "  sub_region_2 = df[df['place_id']==placeid]['sub_region_2'].unique()[0]\n",
        "\n",
        "\n",
        "  new_row = {'place_id'       : placeid,\n",
        "             'iso_3166_2_code': iso_3166_2_code,\n",
        "             'country_region' : country_region, \n",
        "             'sub_region_1'   : sub_region_1, \n",
        "             'sub_region_2'   : sub_region_2\n",
        "            }\n",
        "\n",
        "  #append row to the dataframe\n",
        "  place_id_lookup = place_id_lookup.append(new_row, ignore_index=True)\n",
        "\n",
        "#inspect the place_id_lookup\n",
        "place_id_lookup"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ow4kmCuQQQIh"
      },
      "source": [
        "def get_timestamp():\n",
        "  from datetime import datetime, timezone\n",
        "\n",
        "  #get sydney timezone\n",
        "  import pytz\n",
        "  sydney_tz = pytz.timezone('Australia/Sydney')\n",
        "  now = datetime.now(sydney_tz)\n",
        "\n",
        "  # format to dd/mm/YY H:M:S with timezone\n",
        "  dt_string = now.strftime(\"%d/%m/%Y %H:%M:%S %z\")\n",
        "  return dt_string\n",
        "\n",
        "get_timestamp()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "At971ED49UsI"
      },
      "source": [
        "def write_to_gsheet(workbook_title, worksheet_title, data):\n",
        "  # open spreadsheet\n",
        "  sh = gc.open(workbook_title)\n",
        "\n",
        "  #select an existing worksheet (tab)\n",
        "  worksheet = sh.worksheet(worksheet_title)\n",
        "\n",
        "  #delete that worksheet\n",
        "  sh.del_worksheet(worksheet)\n",
        "\n",
        "  #recreate worksheet (tab) and populate with dataframe\n",
        "  worksheet = sh.add_worksheet(title=worksheet_title, rows=\"1000\", cols=\"200\")\n",
        "  set_with_dataframe(worksheet, data, include_index=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GKIAjFtcA7n7"
      },
      "source": [
        "1. Pivot the data\n",
        "2. Move the 'Australia' label down to the other levels\n",
        "3. Move the State labels down to the sub_region_2\n",
        "\n",
        "\n",
        "\n",
        " "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q4D8MA_73nZB"
      },
      "source": [
        "CATEGORIES = ['retail_and_recreation_percent_change_from_baseline',\n",
        "              'grocery_and_pharmacy_percent_change_from_baseline',\n",
        "              'parks_percent_change_from_baseline',\n",
        "              'transit_stations_percent_change_from_baseline',\n",
        "              'workplaces_percent_change_from_baseline',\n",
        "              'residential_percent_change_from_baseline'\n",
        "            ]\n",
        "\n",
        "# update the fields for AU (sub regions are null for Country)\n",
        "# want unique state values excluding null\n",
        "df.loc[(df.sub_region_1.isnull()) & (df.sub_region_2.isnull()) & (df.iso_3166_2_code.isnull()) & (df['country_region']=='Australia'), 'sub_region_1'] = 'AUS'\n",
        "df.loc[(df.sub_region_2.isnull()) & (df.iso_3166_2_code.isnull()) & (df['country_region']=='Australia'), 'sub_region_2'] = 'AUS'\n",
        "\n",
        "# move the iso_3166_2_code (i.e. state) into sub_region_2\n",
        "# want unique state values excluding null\n",
        "for state in df.iso_3166_2_code.copy().dropna().unique():\n",
        "  df.loc[df['iso_3166_2_code']==state, 'sub_region_2'] = state[3:]\n",
        "\n",
        "\n",
        "cols = ['sub_region_1', 'sub_region_2']\n",
        "\n",
        "\n",
        "# for each category, pivot on that category\n",
        "for category in CATEGORIES:\n",
        "  print(\"processing {}\".format(category))\n",
        "  mobility_data = df.pivot(index = 'date', columns = cols, values=category)\n",
        "\n",
        "  #get rolling average\n",
        "  rolling_mean_df = mobility_data.rolling(7).mean()\n",
        "\n",
        "  #add timestamp\n",
        "  mobility_data['last_updated'] = get_timestamp()\n",
        "  mobility_data_pivoted['last_updated'] = get_timestamp()\n",
        "  rolling_mean_df['last_updated'] = get_timestamp()\n",
        "\n",
        "  #write to googlesheets\n",
        "  write_to_gsheet(workbook_title='mobility_data',\n",
        "                worksheet_title = category.split('_')[0],\n",
        "                data = mobility_data)\n",
        "  \n",
        "  write_to_gsheet(workbook_title='mobility_data_rolling_7day_average',\n",
        "                worksheet_title = category.split('_')[0],\n",
        "                data = rolling_mean_df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3B1VE2frwr1G"
      },
      "source": [
        "print(\"SUCCESS - script has run as of {}\".format(get_timestamp()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DhI_6EZcCqE0"
      },
      "source": [
        "#get LGA data just before lockdown\n",
        "test = df[df.date>='2021-06-01']\n",
        "test = test[['date', 'sub_region_1', 'sub_region_2']+CATEGORIES]\n",
        "\n",
        "write_to_gsheet(workbook_title='TEST_mobility_data_pivoted',\n",
        "              worksheet_title = 'all_categories',\n",
        "              data = test)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}